{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Guide for Long-Short Term Memory Neural Networks (LSTM)\n",
    "\n",
    "This guide recreates the LSTM for Time Series article written by Jason Brownlee for machinelearningmastery.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/azel/github/Data-Science/jupyter_notebooks\n",
      "/Users/azel/github/Data-Science\n",
      "/Users/azel/github/Data-Science/data\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd .. \n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fin_data import DailyTimeSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    \n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(cut, X, y):\n",
    "    \"\"\"\n",
    "    Temporal Train Test Split. Holdout is most recent data.  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Train Test Split: 70% Train, 30% Test\n",
    "    X_train = X[:int(len(X)*cut)]\n",
    "    X_test= X[int(len(X)*cut):len(X)]\n",
    "    y_train=y[:int(len(y)*cut)]\n",
    "    y_test=y[int(len(y)*cut):len(y)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range (len(sequence)):\n",
    "        #find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check to see if we are at the end of the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "                break\n",
    "        #gather input and output parts of the pattern\n",
    "        seq_X, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50] 60\n",
      "[20 30 40 50 60] 70\n",
      "[30 40 50 60 70] 80\n",
      "[40 50 60 70 80] 90\n",
      "[50 60 70 80 90] 100\n",
      "[ 60  70  80  90 100] 110\n",
      "[ 70  80  90 100 110] 120\n",
      "[ 80  90 100 110 120] 130\n",
      "[ 90 100 110 120 130] 140\n",
      "[100 110 120 130 140] 150\n",
      "[110 120 130 140 150] 160\n",
      "[120 130 140 150 160] 170\n",
      "[130 140 150 160 170] 180\n",
      "[140 150 160 170 180] 190\n"
     ]
    }
   ],
   "source": [
    "raw_seq = np.arange(start=10, stop=200, step=10)\n",
    "n_steps = 5\n",
    "\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/envs/black_swan/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c345780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating next input\n",
    "x_input = np.array([150, 160, 170,180,190])\n",
    "#reshaping to the proper sequence\n",
    "x_input = x_input.reshape((1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prediction should be 200, is it?\n",
      "prediction:  198.98883\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_input, verbose=0)\n",
    "print('The Prediction should be 200, is it?')\n",
    "print('prediction: ', y_pred[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply this to the S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################### \n",
      " Ticker:  AAPL \n",
      " Last Refreshed:  2019-09-03 11:03:23 \n",
      " Data Retrieved:  Daily Prices (open, high, low, close) and Volumes \n",
      " ###################################################################\n"
     ]
    }
   ],
   "source": [
    "#Get data for Apple\n",
    "apple = DailyTimeSeries('AAPL')\n",
    "adf = apple.initiate()\n",
    "#Create Univariate Time Series \n",
    "data = adf[['AAPL close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var1(t)\n",
       "1        0.0        1\n",
       "2        1.0        2\n",
       "3        2.0        3\n",
       "4        3.0        4\n",
       "5        4.0        5\n",
       "6        5.0        6\n",
       "7        6.0        7\n",
       "8        7.0        8\n",
       "9        8.0        9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "\n",
    "values = [x for x in range(10)]\n",
    "d = series_to_supervised(values)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = series_to_supervised(data=data, n_in=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='var1(t)')\n",
    "y = data['var1(t)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(cut=0.8, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007/1007 [==============================] - 0s 24us/step\n",
      "Neural Network MSE:  8.19445793583708\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=200,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=0)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print('Neural Network MSE: ', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM\n",
    "\n",
    "Multiple hidden LSTM layers can be stacked one on top of another in what is referred to as a Stacked LSTM model.\n",
    "\n",
    "An LSTM layer requires a three-dimensional input and LSTMs by default will produce a two-dimensional output as an interpretation from the end of the sequence.\n",
    "\n",
    "We can address this by having the LSTM output a value for each time step in the input data by setting the return_sequences=True argument on the layer. This allows us to have 3D output from hidden LSTM layer as input to the next.\n",
    "\n",
    "We can therefore define a Stacked LSTM as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007/1007 [==============================] - 0s 29us/step\n",
      "Neural Network MSE:  9.247217992803428\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=200,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=0)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print('Neural Network MSE: ', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.\n",
    "\n",
    "This is called a Bidirectional LSTM.\n",
    "\n",
    "We can implement a Bidirectional LSTM for univariate time series forecasting by wrapping the first hidden layer in a wrapper layer called Bidirectional.\n",
    "\n",
    "An example of defining a Bidirectional LSTM to read input both forward and backward is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007/1007 [==============================] - 0s 23us/step\n",
      "Neural Network MSE:  7.887479213403969\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=200,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=0)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print('Neural Network MSE: ', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  45,  65,  85, 105, 125, 145, 165, 185])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Input\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "#Create target\n",
    "out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,  25],\n",
       "       [ 20,  25,  45],\n",
       "       [ 30,  35,  65],\n",
       "       [ 40,  45,  85],\n",
       "       [ 50,  55, 105],\n",
       "       [ 60,  65, 125],\n",
       "       [ 70,  75, 145],\n",
       "       [ 80,  85, 165],\n",
       "       [ 90,  95, 185]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 2) (7,) \n",
      "\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "print(X.shape, y.shape,'\\n')\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the X component has a three-dimensional structure.\n",
    "\n",
    "The first dimension is the number of samples, in this case 7. The second dimension is the number of time steps per sample, in this case 3, the value specified to the function. Finally, the last dimension specifies the number of parallel time series or the number of variables, in this case 2 for the two parallel series.\n",
    "\n",
    "This is the exact three-dimensional structure expected by an LSTM as input. The data is ready to use without further reshaping.\n",
    "\n",
    "We can then see that the input and output for each sample is printed, showing the three time steps for each of the two input series and the associated output for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[209.71779]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "model.predict(x_input, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with Apple's data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
